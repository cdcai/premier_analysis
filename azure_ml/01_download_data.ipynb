{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Download data from Azure Data Lake Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from azureml.core import Workspace, Datastore, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create Datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "adlsgen2_datastore_name = 'adlsgen2datastore'\n",
        "\n",
        "subscription_id=os.getenv(\"ADL_SUBSCRIPTION\", \"<my_subscription_id>\") # subscription id of ADLS account\n",
        "resource_group=os.getenv(\"ADL_RESOURCE_GROUP\", \"<my_resource_group>\") # resource group of ADLS account\n",
        "\n",
        "account_name=os.getenv(\"ADLSGEN2_ACCOUNTNAME\", \"<my_account_name>\") # ADLS Gen2 account name\n",
        "tenant_id=os.getenv(\"ADLSGEN2_TENANT\", \"<my_tenant_id>\") # tenant id of service principal\n",
        "client_id=os.getenv(\"ADLSGEN2_CLIENTID\", \"<my_client_id>\") # client id of service principal\n",
        "client_secret=os.getenv(\"ADLSGEN2_CLIENT_SECRET\", \"<my_client_secret>\") # the secret of service principal\n",
        "\n",
        "adlsgen2_datastore = Datastore.register_azure_data_lake_gen2(workspace=ws,\n",
        "                                                             datastore_name=adlsgen2_datastore_name,\n",
        "                                                             account_name=account_name, # ADLS Gen2 account name\n",
        "                                                             filesystem='test', # ADLS Gen2 filesystem\n",
        "                                                             tenant_id=tenant_id, # tenant id of service principal\n",
        "                                                             client_id=client_id, # client id of service principal\n",
        "                                                             client_secret=client_secret) # the secret of service principal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Get the datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1664481157228
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "datastore_name = 'edav_dev_ds'\n",
        "cdh_path = 'exploratory/databricks_ml/mitre_premier/data/'\n",
        "\n",
        "datasets_path_name =  ['vw_covid_pat','vw_covid_id','vw_covid_genlab',\n",
        "                            'vw_covid_hx_genlab','vw_covid_lab_res','vw_covid_hx_lab_res','vw_covid_vitals',\n",
        "                            'vw_covid_hx_vitals','vw_covid_bill_lab','vw_covid_bill_pharm','vw_covid_bill_oth',\n",
        "                            'vw_covid_hx_bill','vw_covid_paticd_diag','vw_covid_paticd_proc','vw_covid_additional_paticd_diag',\n",
        "                            'vw_covid_additional_paticd_proc','icdcode']\n",
        "\n",
        "# get existing workspace\n",
        "workspace = Workspace.from_config()\n",
        "    \n",
        "# retrieve an existing datastore in the workspace by name\n",
        "datastore = Datastore.get(workspace, datastore_name)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1664481157359
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/azure_ml\n",
            "\n",
            "Parent Directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis\n"
          ]
        }
      ],
      "source": [
        "# current working directory\n",
        "path = os.getcwd()\n",
        "print(\"Current Directory:\", path)\n",
        "  \n",
        "# parent directory\n",
        "parent = os.path.join(path, os.pardir)\n",
        "  \n",
        "# prints parent directory\n",
        "print(\"\\nParent Directory:\", os.path.abspath(parent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1664481157487
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "premier_path = os.path.abspath(parent)\n",
        "cdh_path = 'exploratory/databricks_ml/mitre_premier/data/'\n",
        "#for _path_name in datasets_path_name[9:]:\n",
        "#    print(f\"Downloading data :{_path_name}.....\")\n",
        "#    \n",
        "    # Azure data lake storage path\n",
        "#    patient_datapath = os.path.join(cdh_path,_path_name)\n",
        "    # print(patient_datapath)\n",
        "#    datastore_paths = [(datastore, patient_datapath)]\n",
        "\n",
        "    #load parquet files from # Azure data lake storage\n",
        "#    ds = Dataset.File.from_files(path= datastore_paths)\n",
        "\n",
        "    # local path to download data\n",
        "#    download_data_path = os.path.join(premier_path,'data/data/',_path_name)\n",
        "     # create folder\n",
        "#    os.makedirs(download_data_path,exist_ok=True)\n",
        "\n",
        "#    ds.download(target_path=download_data_path,overwrite=True,ignore_not_found=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1664481157598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "def download_files(_path_name):\n",
        "    print(f\"Downloading data :{_path_name}.....\")\n",
        "    \n",
        "    # Azure data lake storage path\n",
        "    patient_datapath = os.path.join(cdh_path,_path_name)\n",
        "    # print(patient_datapath)\n",
        "    datastore_paths = [(datastore, patient_datapath)]\n",
        "\n",
        "    #load parquet files from # Azure data lake storage\n",
        "    ds = Dataset.File.from_files(path= datastore_paths)\n",
        "\n",
        "    # local path to download data\n",
        "    download_data_path = os.path.join(premier_path,'data/data/',_path_name)\n",
        "     # create folder\n",
        "    os.makedirs(download_data_path,exist_ok=True)\n",
        "\n",
        "    ds.download(target_path=download_data_path,overwrite=True,ignore_not_found=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1664477974827
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data :vw_covid_pat.....\n",
            "Downloading data :vw_covid_id.....\n",
            "Downloading data :vw_covid_genlab.....\n",
            "Downloading data :vw_covid_hx_genlab.....\n",
            "Downloading data :vw_covid_lab_res.....\n",
            "Downloading data :vw_covid_hx_lab_res.....\n",
            "Downloading data :vw_covid_vitals.....\n",
            "Downloading data :vw_covid_hx_vitals.....\n",
            "Downloading data :vw_covid_bill_lab.....\n",
            "Downloading data :vw_covid_bill_pharm.....\n",
            "Downloading data :vw_covid_bill_oth.....\n",
            "Downloading data :vw_covid_hx_bill.....\n",
            "Downloading data :vw_covid_paticd_diag.....\n",
            "Downloading data :vw_covid_paticd_proc.....\n",
            "Downloading data :vw_covid_additional_paticd_diag.....\n",
            "Downloading data :vw_covid_additional_paticd_proc.....\n",
            "Downloading data :icdcode.....\n"
          ]
        }
      ],
      "source": [
        "datasets_path_name =  ['vw_covid_pat','vw_covid_id','vw_covid_genlab',\n",
        "                            'vw_covid_hx_genlab','vw_covid_lab_res','vw_covid_hx_lab_res','vw_covid_vitals',\n",
        "                            'vw_covid_hx_vitals','vw_covid_bill_lab','vw_covid_bill_pharm','vw_covid_bill_oth',\n",
        "                            'vw_covid_hx_bill','vw_covid_paticd_diag','vw_covid_paticd_proc','vw_covid_additional_paticd_diag',\n",
        "                            'vw_covid_additional_paticd_proc','icdcode','vw_covid_pat_all','providers']\n",
        "\n",
        "for ds_name in datasets_path_name:\n",
        "    download_files(ds_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1664481187482
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data :providers.....\n"
          ]
        }
      ],
      "source": [
        "download_files(\"providers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### ICU Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1664477652426
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exploratory/databricks_ml/mitre_premier/targets/icu_targets.csv\n"
          ]
        }
      ],
      "source": [
        "cdh_path = 'exploratory/databricks_ml/mitre_premier/targets/'\n",
        "\n",
        "# Azure data lake storage path\n",
        "icu_datapath = os.path.join(cdh_path,'icu_targets.csv')\n",
        "print(icu_datapath)\n",
        "datastore_icu_paths = [(datastore, icu_datapath)]\n",
        "\n",
        "#load parquet files from # Azure data lake storage\n",
        "ds = Dataset.File.from_files(path= datastore_icu_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1664477660119
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "  \"source\": [\n",
              "    \"('edav_dev_ds', 'exploratory/databricks_ml/mitre_premier/targets/icu_targets.csv')\"\n",
              "  ],\n",
              "  \"definition\": [\n",
              "    \"GetDatastoreFiles\"\n",
              "  ]\n",
              "}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1664477669039
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/data/targets/icu_targets.csv']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "premier_path = os.path.abspath(parent)\n",
        "print(premier_path)\n",
        "# local path to download data\n",
        "download_data_path_icu = os.path.join(premier_path,'data/targets/')\n",
        "# create folder\n",
        "os.makedirs(download_data_path_icu,exist_ok=True)\n",
        "ds.download(target_path=download_data_path_icu,overwrite=True,ignore_not_found=True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Cohort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1664477592389
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/cohort.csv']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cdh_path = 'exploratory/databricks_ml/mitre_premier/output/'\n",
        "\n",
        "# Azure data lake storage path\n",
        "_datapath = os.path.join(cdh_path,'cohort.csv')\n",
        "# print(patient_datapath)\n",
        "datastore_paths = [(datastore, _datapath)]\n",
        "\n",
        "#load parquet files from # Azure data lake storage\n",
        "ds = Dataset.File.from_files(path= datastore_paths)\n",
        "premier_path = os.path.abspath(parent)\n",
        "print(premier_path)\n",
        "# local path to download data\n",
        "download_data_path_cohort = os.path.join(premier_path,'output')\n",
        "# create folder\n",
        "os.makedirs(download_data_path_cohort,exist_ok=True)\n",
        "ds.download(target_path=download_data_path_cohort,overwrite=True,ignore_not_found=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 ('azureml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "c29d249f6248e1876db3a43ab8bde2e53ec2cf908dd5eb31493a2d1f2322e9b6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
