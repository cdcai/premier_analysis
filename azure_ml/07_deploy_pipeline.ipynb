{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "from azureml.core import  Workspace\r\n",
        "from azureml.core import Model\r\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "from azureml.core.environment import Environment \r\n",
        "from azureml.core.webservice import AciWebservice,Webservice\r\n",
        "from azureml.core.model import Model,InferenceConfig\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE, DEFAULT_GPU_IMAGE\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"9ce70869-60db-44fd-abe8-d2767077fc8f\")\r\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1664907163954
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Workspace name: ' + ws.name, \r\n",
        "      'Azure region: ' + ws.location, \r\n",
        "      'Subscription id: ' + ws.subscription_id, \r\n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: cdh-azml-dev-mlw\nAzure region: eastus\nSubscription id: 320d8d57-c87c-4434-827f-59ee7d86687a\nResource group: csels-cdh-dev\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664907166069
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(workspace=ws,name='dan_d1_misa_pt',version=2)\r\n",
        "print(os.getenv(\"AZUREML_MODEL_DIR\"))\r\n",
        "#model_path = Model.get_model_path(os.getenv(\"AZUREML_MODEL_DIR\").split('/')[-2])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "None\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664907918274
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "os.makedirs('./aml_outputs/',exist_ok=True)\r\n",
        "model.download(target_dir='./aml_outputs/',exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "'aml_outputs/dan_d1_misa_pt'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664907941682
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\r\n",
        "import tensorflow as tf\r\n",
        "loaded_model = keras.models.load_model('aml_outputs/dan_d1_misa_pt.h5/')"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664907611999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\r\n",
        "from tensorflow import keras\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "# tensorflow version must match training version\r\n",
        "loaded_model = keras.models.load_model('aml_outputs/dan_d1_misa_pt/',custom_objects={'tf':tf},compile=True)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664907951872
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.10.0\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664907292081
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\r\n",
        "from azureml.core import Run\r\n",
        "data_store = ws.get_default_datastore()\r\n",
        "\r\n",
        "##########Loading the data from datastore\r\n",
        "print(\"Creating dataset from Datastore\")\r\n",
        "inputs = Dataset.File.from_files(path=data_store.path('pkl/trimmed_seqs.pkl'))\r\n",
        "vocab = Dataset.File.from_files(path=data_store.path('pkl/all_ftrs_dict.pkl'))\r\n",
        "demog_dict = Dataset.File.from_files(path=data_store.path('pkl/demog_dict.pkl'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating dataset from Datastore\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664908877517
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.download(target_path='./',overwrite=True,ignore_not_found=True)\r\n",
        "vocab.download(target_path='./',overwrite=True,ignore_not_found=True)\r\n",
        "demog_dict.download(target_path='./',overwrite=True,ignore_not_found=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/azure_ml/demog_dict.pkl']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909025950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\r\n",
        "with open(\"trimmed_seqs.pkl\", \"rb\") as f:\r\n",
        "    inputs = pkl.load(f)\r\n",
        "\r\n",
        "with open(os.path.join(\"all_ftrs_dict.pkl\"), \"rb\") as f:\r\n",
        "        vocab = pkl.load(f)\r\n",
        "\r\n",
        "with open(os.path.join(\"demog_dict.pkl\"), \"rb\") as f:\r\n",
        "        demog_lookup = pkl.load(f)"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909086162
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909119944
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [l[0][-1] for l in inputs]\r\n",
        "N_VOCAB = len(vocab) + 1\r\n",
        "N_DEMOG = len(demog_lookup) + 1"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909188442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_VOCAB,N_DEMOG"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "(44727, 18)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909193616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_demog = [[i + N_VOCAB - 1 for i in l[1]] for l in inputs]\r\n",
        "features = [\r\n",
        "                features[i] + new_demog[i] for i in range(len(features))\r\n",
        "            ]\r\n",
        "demog_vocab = {k: v + N_VOCAB - 1 for k, v in demog_lookup.items()}\r\n",
        "vocab.update(demog_vocab)\r\n",
        "N_VOCAB = np.max([np.max(l) for l in features]) + 1"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909204833
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\r\n",
        "X = keras.preprocessing.sequence.pad_sequences(features,padding='post')\r\n",
        "X.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "(67562, 1895)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909215100
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = X[0]\r\n",
        "test = np.expand_dims(test,axis=0)\r\n",
        "test.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "(1, 1895)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909606330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = loaded_model.predict(test)\r\n",
        "preds.shape"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 20ms/step\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "(1, 1)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909619638
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploying Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "array([0.06474929], dtype=float32)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664909626816
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies_score.yml\r\n",
        "channels:\r\n",
        "- anaconda\r\n",
        "- default\r\n",
        "dependencies:\r\n",
        "- python=3.8\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - matplotlib\r\n",
        "  - pandas\r\n",
        "  - argparse\r\n",
        "  - joblib\r\n",
        "  - inference-schema[numpy-support]\r\n",
        "  - scikit-learn\r\n",
        "  - azureml-sdk\r\n",
        "  - openpyxl\r\n",
        "  - tensorflow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting conda_dependencies_score.yml\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "premier_train_score_env = Environment.from_conda_specification(name='premier_train_model_env', file_path='conda_dependencies_score.yml')\r\n",
        "# Specify a CPU base image\r\n",
        "# premier_train_model_env.docker.enabled = True\r\n",
        "premier_train_score_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "premier_train_score_env.register(workspace=ws)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Inference Configuration\r\n",
        "\r\n",
        "* file_path: input parameter to Environment constructor. Manages conda and python package dependencies.\r\n",
        "* env.docker.base_dockerfile: any extra steps you want to inject into docker file\r\n",
        "* source_directory: holds source path as string, this entire folder gets added in image so its really easy to access any files within this folder or subfolder\r\n",
        "* entry_script: contains logic specific to initializing your model and running predictions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "MOD_NAME = 'dan'\r\n",
        "OUTCOME = 'misa_pt'\r\n",
        "service_name = f\"premier-model-{MOD_NAME}-{OUTCOME}\"\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script='./training/score.py', environment=premier_train_score_env)\r\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1,\r\n",
        "                                                memory_gb=1 )\r\n",
        "\r\n",
        "\r\n",
        "service = Model.deploy(workspace=ws,\r\n",
        "                       name=service_name,\r\n",
        "                       models=[model],\r\n",
        "                       inference_config=inference_config,\r\n",
        "                       deployment_config=aci_config,\r\n",
        "                       overwrite=True)\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "premier_train_model_env",
      "language": "python",
      "display_name": "premier train"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "premier_train_model_env"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}