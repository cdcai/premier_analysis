{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments Premier Analysis on Azure Machine Learning\n",
        "### Baseline models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import sklearn\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from azureml.core import Run, Dataset, Environment,Experiment,ScriptRunConfig\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1664484960308
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import  Workspace\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"9ce70869-60db-44fd-abe8-d2767077fc8f\")\n",
        "\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664484974827
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: cdh-azml-dev-mlw\nAzure region: eastus\nSubscription id: 320d8d57-c87c-4434-827f-59ee7d86687a\nResource group: csels-cdh-dev\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1664484978004
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# current working directory\n",
        "path = os.getcwd()\n",
        "print(\"Current Directory:\", path)\n",
        "  \n",
        "# parent directory\n",
        "parent = os.path.join(path, os.pardir)\n",
        "  \n",
        "# prints parent directory\n",
        "print(\"\\nParent Directory:\", os.path.abspath(parent))\n",
        "\n",
        "premier_path = os.path.abspath(parent)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current Directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/azure_ml\n\nParent Directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1664484978143
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Compute"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clustername = 'StandardDS3v2'\n",
        "is_new_cluster = False\n",
        "try:\n",
        "    aml_cluster = ComputeTarget(workspace = ws,name= clustername)\n",
        "    print(\"Find the existing cluster\")\n",
        "except ComputeTargetException:\n",
        "    print(\"Cluster not find - Creating cluster.....\")\n",
        "    is_new_cluster = True\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2',\n",
        "                                                           max_nodes=4)\n",
        "    aml_cluster = ComputeTarget.create(ws, clustername, compute_config)\n",
        "\n",
        "aml_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Find the existing cluster\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1664484987526
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features_path = os.path.join(premier_path,'output/parquet')\n",
        "features_pkl = os.path.join(premier_path,'output/pkl')\n",
        "\n",
        "\n",
        "data_store = ws.get_default_datastore()\n",
        "data_store.upload(src_dir=features_path,target_path='parquet',overwrite=True,show_progress=True)\n",
        "data_store.upload(src_dir=features_pkl,target_path='pkl',overwrite=True,show_progress=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 3 files\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/parquet/.amlignore\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/parquet/.amlignore, 1 files out of an estimated total of 3\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/parquet/.amlignore.amltmp\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/parquet/.amlignore.amltmp, 2 files out of an estimated total of 3\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/parquet/flat_features.parquet\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/parquet/flat_features.parquet, 3 files out of an estimated total of 3\nUploaded 3 files\nUploading an estimated of 8 files\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/.amlignore\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/.amlignore, 1 files out of an estimated total of 8\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/.amlignore.amltmp\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/.amlignore.amltmp, 2 files out of an estimated total of 8\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/all_ftrs_dict.pkl\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/all_ftrs_dict.pkl, 3 files out of an estimated total of 8\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/demog_dict.pkl\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/demog_dict.pkl, 4 files out of an estimated total of 8\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/feature_lookup.pkl\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/feature_lookup.pkl, 5 files out of an estimated total of 8\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/pat_data.pkl\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/pat_data.pkl, 6 files out of an estimated total of 8\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/trimmed_seqs.pkl\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/trimmed_seqs.pkl, 7 files out of an estimated total of 8\nUploading /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/int_seqs.pkl\nUploaded /mnt/batch/tasks/shared/LS_root/mounts/clusters/wsn8-su2/code/Users/WSN8-SU/premier_analysis/output/pkl/int_seqs.pkl, 8 files out of an estimated total of 8\nUploaded 8 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_b316ff3989b94fbbb31f5761241683f7"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1664485104381
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cohort_path = os.path.join(premier_path,'output/cohort')\n",
        "data_store.upload(src_dir=cohort_path,target_path='cohort',overwrite=True,show_progress=True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "UserErrorException",
          "evalue": "UserErrorException:\n\tMessage: src_path must be a directory.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"src_path must be a directory.\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
            "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cohort_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(premier_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/cohort\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdata_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcohort_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcohort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_deprecation.py:26\u001b[0m, in \u001b[0;36mdeprecated.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     _warn_deprecation(target, replacement)  \u001b[38;5;66;03m# only raise warning for top-level invocation\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     _warning_silenced_for \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m---> 26\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _warning_silenced_for \u001b[38;5;241m==\u001b[39m target:\n\u001b[1;32m     28\u001b[0m     _warning_silenced_for \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/azure_storage_datastore.py:793\u001b[0m, in \u001b[0;36mAzureBlobDatastore.upload\u001b[0;34m(self, src_dir, target_path, overwrite, show_progress)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_credential(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    791\u001b[0m target_path \u001b[38;5;241m=\u001b[39m target_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_upload_task(\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_upload_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    794\u001b[0m     overwrite,\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m target_file_path: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_service\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_name, target_file_path),\n\u001b[1;32m    796\u001b[0m     show_progress,\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m target, source: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_service\u001b[38;5;241m.\u001b[39mcreate_blob_from_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_name, target, source)\n\u001b[1;32m    798\u001b[0m )\n\u001b[1;32m    799\u001b[0m module_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished AzureBlobDatastore.upload with count=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(count))\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataReference(datastore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, path_on_datastore\u001b[38;5;241m=\u001b[39mtarget_path)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/azure_storage_datastore.py:270\u001b[0m, in \u001b[0;36mAbstractAzureStorageDatastore._get_upload_from_dir\u001b[0;34m(self, src_path, target_path)\u001b[0m\n\u001b[1;32m    268\u001b[0m src_path \u001b[38;5;241m=\u001b[39m src_path\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(src_path):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_path must be a directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    272\u001b[0m paths_to_upload \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirpath, dirnames, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(src_path):\n",
            "\u001b[0;31mUserErrorException\u001b[0m: UserErrorException:\n\tMessage: src_path must be a directory.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"src_path must be a directory.\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1664485105320
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies_baseline.yml\n",
        "\n",
        "channels:\n",
        "- anaconda\n",
        "- default\n",
        "dependencies:\n",
        "- python=3.8\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - matplotlib\n",
        "  - pandas\n",
        "  - argparse\n",
        "  - joblib\n",
        "  - scikit-learn\n",
        "  - azureml-sdk\n",
        "  - openpyxl"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting conda_dependencies_baseline.yml\n"
        }
      ],
      "execution_count": 85,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "premier_train_baseline_env = Environment.from_conda_specification(name='premier_train_baseline_env', file_path='conda_dependencies_baseline.yml')\n",
        "# Specify a CPU base image\n",
        "premier_train_baseline_env.docker.enabled = True\n",
        "premier_train_baseline_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "premier_train_baseline_env.register(workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664485105407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = Experiment(workspace=ws, name=\"Premier-Baseline-models\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1664485105423
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create script config\n",
        "\n",
        "#mod_names = ['lgr', 'rf', 'gbc', 'svm']\n",
        "mod_names = ['svm']\n",
        "for mod in mod_names:\n",
        "    estimator = ScriptRunConfig(source_directory='./training',\n",
        "                          script='train_baseline.py',\n",
        "                          compute_target=aml_cluster,\n",
        "                           arguments=['--day_one','--outcome', 'icu','--model', mod],\n",
        "                          environment=premier_train_baseline_env)\n",
        "    # Create experiment\n",
        "    experiment = Experiment(workspace=ws, name=f\"Premier-Baseline-model-{mod}\")\n",
        "    \n",
        "    print(\"Submit Experiment\")\n",
        "    run = experiment.submit(estimator)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submit Experiment\nSubmit Experiment\nSubmit Experiment\nSubmit Experiment\n"
        }
      ],
      "execution_count": 107,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#run.wait_for_completion(show_output=False,\n",
        "#                          wait_post_processing=False,\n",
        "#                         raise_on_error=True)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submit Experiment\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 106,
          "data": {
            "text/plain": "{'runId': 'Premier-Baseline-models_1663976158_1e055d5e',\n 'target': 'StandardDS3v2',\n 'status': 'Completed',\n 'startTimeUtc': '2022-09-23T23:36:19.750038Z',\n 'endTimeUtc': '2022-09-23T23:45:34.036832Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n  'ContentSnapshotId': '25b3bf30-91a2-40a3-8c18-295a34b26852',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'train_baseline.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--day_one', '--outcome', 'misa_pt'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'StandardDS3v2',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'premier_train_baseline_env',\n   'version': '2',\n   'assetId': 'azureml://locations/eastus/workspaces/d5539876-73f2-429b-9d16-cd4969e1602d/environments/premier_train_baseline_env/versions/2',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'channels': ['anaconda', 'default'],\n     'dependencies': ['python=3.8',\n      {'pip': ['azureml-defaults',\n        'matplotlib',\n        'pandas',\n        'argparse',\n        'joblib',\n        'scikit-learn',\n        'azureml-sdk',\n        'openpyxl']}]},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220616.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': True,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'logs/azureml/dataprep/0/rslex.log.2022-09-23-23': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/logs/azureml/dataprep/0/rslex.log.2022-09-23-23?sv=2019-07-07&sr=b&sig=3jRMY7HDon22Cg6xN1VQIT1CIntut8z0WcOgZWU1REs%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A40Z&se=2022-09-24T07%3A45%3A40Z&sp=r',\n  'user_logs/std_log.txt': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=Ggzc8uxRlUPqkPlPV3DQD%2FGVmKcfDhO8WGj1ddbNwmo%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A43Z&se=2022-09-24T07%3A45%3A43Z&sp=r',\n  'system_logs/cs_capability/cs-capability.log': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=7ytYVC%2B%2Bj4hs70qSdjc743exQSl%2FKmgqdwwTAt15hIE%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A46Z&se=2022-09-24T07%3A45%3A46Z&sp=r',\n  'system_logs/hosttools_capability/hosttools-capability.log': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=QQ%2FP3fSFVIl6MqCzND%2FIfPgUz8mJktqJmTRslFM5Hks%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A46Z&se=2022-09-24T07%3A45%3A46Z&sp=r',\n  'system_logs/lifecycler/execution-wrapper.log': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=J0bgAjUMyOEgrO80hEymPhMNDWVuLrFfGDR9yeHyEh4%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A46Z&se=2022-09-24T07%3A45%3A46Z&sp=r',\n  'system_logs/lifecycler/lifecycler.log': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=7P4RaY3%2BxfsTU7zNEwMjFjReoJbFH0CUDgAt0ypWyCg%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A46Z&se=2022-09-24T07%3A45%3A46Z&sp=r',\n  'system_logs/metrics_capability/metrics-capability.log': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=DwM7oRUNHik2YaV5vcRKQS5qXXtndtaFV8pmznI%2Fxeg%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A46Z&se=2022-09-24T07%3A45%3A46Z&sp=r',\n  'system_logs/snapshot_capability/snapshot-capability.log': 'https://cdhazmldevstyt3g.blob.core.windows.net/azureml/ExperimentRun/dcid.Premier-Baseline-models_1663976158_1e055d5e/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=5otAL9PqXvVv1Ryh0Qzv8JIQRqroy4FcoHA1YKHVsyU%3D&skoid=2c3a2c62-885b-455c-86d5-29aff5b6bc6a&sktid=9ce70869-60db-44fd-abe8-d2767077fc8f&skt=2022-09-23T18%3A48%3A39Z&ske=2022-09-25T02%3A58%3A39Z&sks=b&skv=2019-07-07&st=2022-09-23T23%3A35%3A46Z&se=2022-09-24T07%3A45%3A46Z&sp=r'},\n 'submittedBy': 'Mayer Antoine'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 106,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}