{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Deep Learning Models Experiments -  Premier Analysis on Azure Machine Learning\n",
        "### LSTM and DAN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1664901002082
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import sklearn\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from azureml.core import Run, Dataset, Environment,Experiment,ScriptRunConfig\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1664901014913
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import  Workspace\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"9ce70869-60db-44fd-abe8-d2767077fc8f\")\n",
        "\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1664901015035
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workspace name: cdh-azml-dev-mlw\n",
            "Azure region: eastus\n",
            "Subscription id: 320d8d57-c87c-4434-827f-59ee7d86687a\n",
            "Resource group: csels-cdh-dev\n"
          ]
        }
      ],
      "source": [
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1664901015130
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Directory: c:\\Users\\wsn8\\Code\\premier_analysis\\azure_ml\n",
            "\n",
            "Parent Directory: c:\\Users\\wsn8\\Code\\premier_analysis\n"
          ]
        }
      ],
      "source": [
        "# current working directory\n",
        "path = os.getcwd()\n",
        "print(\"Current Directory:\", path)\n",
        "  \n",
        "# parent directory\n",
        "parent = os.path.join(path, os.pardir)\n",
        "  \n",
        "# prints parent directory\n",
        "print(\"\\nParent Directory:\", os.path.abspath(parent))\n",
        "\n",
        "premier_path = os.path.abspath(parent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create Compute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1664901021480
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Find the existing cluster\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "source": [
        "clustername = 'StandardNC6'\n",
        "is_new_cluster = False\n",
        "try:\n",
        "    aml_cluster_gpu = ComputeTarget(workspace = ws,name= clustername)\n",
        "    print(\"Find the existing cluster\")\n",
        "except ComputeTargetException:\n",
        "    print(\"Cluster not find - Creating cluster.....\")\n",
        "    is_new_cluster = True\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='StandardNC6',\n",
        "                                                           max_nodes=2)\n",
        "    aml_cluster_gpu = ComputeTarget.create(ws, clustername, compute_config)\n",
        "\n",
        "aml_cluster_gpu.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment for deep model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting conda_dependencies_model.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile conda_dependencies_model.yml\n",
        "\n",
        "channels:\n",
        "- anaconda\n",
        "- default\n",
        "dependencies:\n",
        "- python=3.8\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - matplotlib\n",
        "  - pandas\n",
        "  - argparse\n",
        "  - joblib\n",
        "  - scikit-learn\n",
        "  - azureml-sdk\n",
        "  - openpyxl\n",
        "  - tensorflow\n",
        "  - keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1664901067951
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "    \"databricks\": {\n",
              "        \"eggLibraries\": [],\n",
              "        \"jarLibraries\": [],\n",
              "        \"mavenLibraries\": [],\n",
              "        \"pypiLibraries\": [],\n",
              "        \"rcranLibraries\": []\n",
              "    },\n",
              "    \"docker\": {\n",
              "        \"arguments\": [],\n",
              "        \"baseDockerfile\": null,\n",
              "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1\",\n",
              "        \"baseImageRegistry\": {\n",
              "            \"address\": null,\n",
              "            \"password\": null,\n",
              "            \"registryIdentity\": null,\n",
              "            \"username\": null\n",
              "        },\n",
              "        \"enabled\": true,\n",
              "        \"platform\": {\n",
              "            \"architecture\": \"amd64\",\n",
              "            \"os\": \"Linux\"\n",
              "        },\n",
              "        \"sharedVolumes\": true,\n",
              "        \"shmSize\": null\n",
              "    },\n",
              "    \"environmentVariables\": {\n",
              "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
              "    },\n",
              "    \"inferencingStackVersion\": null,\n",
              "    \"name\": \"premier_train_model_env\",\n",
              "    \"python\": {\n",
              "        \"baseCondaEnvironment\": null,\n",
              "        \"condaDependencies\": {\n",
              "            \"channels\": [\n",
              "                \"anaconda\",\n",
              "                \"default\"\n",
              "            ],\n",
              "            \"dependencies\": [\n",
              "                \"python=3.8\",\n",
              "                {\n",
              "                    \"pip\": [\n",
              "                        \"azureml-defaults\",\n",
              "                        \"matplotlib\",\n",
              "                        \"pandas\",\n",
              "                        \"argparse\",\n",
              "                        \"joblib\",\n",
              "                        \"scikit-learn\",\n",
              "                        \"azureml-sdk\",\n",
              "                        \"openpyxl\",\n",
              "                        \"tensorflow\",\n",
              "                        \"keras-tuner\"\n",
              "                    ]\n",
              "                }\n",
              "            ]\n",
              "        },\n",
              "        \"condaDependenciesFile\": null,\n",
              "        \"interpreterPath\": \"python\",\n",
              "        \"userManagedDependencies\": false\n",
              "    },\n",
              "    \"r\": null,\n",
              "    \"spark\": {\n",
              "        \"packages\": [],\n",
              "        \"precachePackages\": true,\n",
              "        \"repositories\": []\n",
              "    },\n",
              "    \"version\": \"13\"\n",
              "}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "premier_train_model_env = Environment.from_conda_specification(name='premier_train_model_env', file_path='conda_dependencies_model.yml')\n",
        "# Specify a GPU base image\n",
        "premier_train_model_env.docker.enabled = True\n",
        "premier_train_model_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "premier_train_model_env.register(workspace=ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiments : Use only first inpatient day's worth of features (--day_one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1664902146893
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submit Experiment: Job-train-deepmodel-d1-icu-dan\n",
            "Submit Experiment: Job-train-deepmodel-d1-icu-lstm\n",
            "Submit Experiment: Job-train-deepmodel-d1-death-dan\n",
            "Submit Experiment: Job-train-deepmodel-d1-death-lstm\n",
            "Submit Experiment: Job-train-deepmodel-d1-misa_pt-dan\n",
            "Submit Experiment: Job-train-deepmodel-d1-misa_pt-lstm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mod_names = ['dan','lstm']\n",
        "outcomes = ['icu','death','misa_pt']\n",
        "#outcomes = ['misa_pt']\n",
        "EPOCHS = 1\n",
        "for outcome in outcomes:\n",
        "    for mod in mod_names:\n",
        "        estimator = ScriptRunConfig(source_directory='./training',\n",
        "                            script='train_model.py',\n",
        "                            compute_target=aml_cluster_gpu,\n",
        "                            arguments=['--day_one','--outcome', outcome,'--model', mod,'--epochs',EPOCHS],\n",
        "                            environment=premier_train_model_env)\n",
        "\n",
        "        exp_name = f\"Job-train-deepmodel-d1-{outcome}-{mod}\"\n",
        "        print(\"Submit Experiment:\",exp_name)\n",
        "        # Create experiment\n",
        "        experiment = Experiment(workspace=ws, name = exp_name)\n",
        "        run = experiment.submit(estimator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experiments: Use all features in lookback period (--all_days)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submit Experiment: Job-train-deepmodel-all_days-icu-dan\n",
            "Submit Experiment: Job-train-deepmodel-all_days-icu-lstm\n",
            "Submit Experiment: Job-train-deepmodel-all_days-death-dan\n",
            "Submit Experiment: Job-train-deepmodel-all_days-death-lstm\n",
            "Submit Experiment: Job-train-deepmodel-all_days-misa_pt-dan\n",
            "Submit Experiment: Job-train-deepmodel-all_days-misa_pt-lstm\n"
          ]
        }
      ],
      "source": [
        "mod_names = ['dan','lstm']\n",
        "outcomes = ['icu','death','misa_pt']\n",
        "#outcomes = ['misa_pt']\n",
        "EPOCHS = 1\n",
        "for outcome in outcomes:\n",
        "    for mod in mod_names:\n",
        "        estimator = ScriptRunConfig(source_directory='./training',\n",
        "                            script='train_model.py',\n",
        "                            compute_target=aml_cluster_gpu,\n",
        "                            arguments=['--all_days','--outcome', outcome,'--model', mod,'--epochs',EPOCHS],\n",
        "                            environment=premier_train_model_env)\n",
        "\n",
        "        exp_name = f\"Job-train-deepmodel-all_days-{outcome}-{mod}\"\n",
        "        print(\"Submit Experiment:\",exp_name)\n",
        "        # Create experiment\n",
        "        experiment = Experiment(workspace=ws, name = exp_name)\n",
        "        run = experiment.submit(estimator)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 ('azureml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "c29d249f6248e1876db3a43ab8bde2e53ec2cf908dd5eb31493a2d1f2322e9b6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
